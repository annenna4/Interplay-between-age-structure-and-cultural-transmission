{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "approximate-frederick",
   "metadata": {},
   "source": [
    "# Classifying Population Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "verbal-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/dataset.py\n",
    "%run ../src/augmentation.py\n",
    "%run ../src/simulation.py\n",
    "%run ../src/nets.py\n",
    "%run ../src/trainer.py\n",
    "%run ../src/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-warning",
   "metadata": {},
   "source": [
    "Train a model based on Wright-Fisher simulations (without age structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cosmetic-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TimeseriesClassifier(\n",
    "    classifier=MultiLayerPerceptron(128, layers=(64, 64, 64)),\n",
    "    embedder=ResNet(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-export",
   "metadata": {},
   "source": [
    "The following cell provides some provisional parameter priors to generate samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worst-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0779,  0.0025,  0.2322])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56.        , 44.41817557, 38.27924108, 34.67361245, 32.27472244,\n",
       "        30.5183134 , 29.14879624]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.distributions import Uniform, Normal\n",
    "\n",
    "neutral_simulator = Simulator(\n",
    "    n_agents=1000,\n",
    "    timesteps=10,\n",
    "    age_window=None,\n",
    "    disable_pbar=True,\n",
    "    summarize=True\n",
    ")\n",
    "\n",
    "prior = IndependentPriors(\n",
    "    Normal(0., 0.1),      # beta prior\n",
    "    Uniform(0.0001, 0.1), # mu prior\n",
    "    Uniform(0.1, 0.5)     # p_death prior\n",
    ")\n",
    "\n",
    "x = prior.sample()\n",
    "print(x)\n",
    "simulator(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-rubber",
   "metadata": {},
   "source": [
    "Train the actual model. In each epoch, we simulate 10k samples with different parameters, $\\theta$. The training procedure can probably be improved, but it already produces reasonable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subjective-oracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: train loss = 0.44, val loss = 0.60, AUC = 0.89\u001b[32m ++\u001b[0m\n",
      "Epoch  2: train loss = 0.32, val loss = 0.32, AUC = 0.92\u001b[32m ++\u001b[0m\n",
      "Epoch  3: train loss = 0.31, val loss = 0.32, AUC = 0.93\u001b[31m --\u001b[0m\n",
      "Epoch  4: train loss = 0.31, val loss = 0.31, AUC = 0.93\u001b[32m ++\u001b[0m\n",
      "Epoch  5: train loss = 0.30, val loss = 0.33, AUC = 0.93\u001b[31m --\u001b[0m\n",
      "Epoch  6: train loss = 0.30, val loss = 0.29, AUC = 0.93\u001b[32m ++\u001b[0m\n",
      "Epoch  7: train loss = 0.29, val loss = 0.28, AUC = 0.93\u001b[32m ++\u001b[0m\n",
      "Epoch  8: train loss = 0.30, val loss = 0.28, AUC = 0.93\u001b[32m ++\u001b[0m\n",
      "Epoch  9: train loss = 0.30, val loss = 0.29, AUC = 0.93\u001b[31m --\u001b[0m\n",
      "Epoch 10: train loss = 0.30, val loss = 0.28, AUC = 0.94\u001b[32m ++\u001b[0m\n",
      "Epoch 11: train loss = 0.28, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 12: train loss = 0.29, val loss = 0.28, AUC = 0.94\u001b[32m ++\u001b[0m\n",
      "Epoch 13: train loss = 0.29, val loss = 0.29, AUC = 0.93\u001b[31m --\u001b[0m\n",
      "Epoch 14: train loss = 0.29, val loss = 0.31, AUC = 0.93\u001b[31m --\u001b[0m\n",
      "Epoch 15: train loss = 0.28, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 16: train loss = 0.28, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 17: train loss = 0.28, val loss = 0.30, AUC = 0.93\u001b[31m --\u001b[0m\n",
      "Epoch 18: train loss = 0.27, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 19: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[32m ++\u001b[0m\n",
      "Epoch 20: train loss = 0.27, val loss = 0.27, AUC = 0.94\u001b[32m ++\u001b[0m\n",
      "Epoch 21: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[32m ++\u001b[0m\n",
      "Epoch 22: train loss = 0.28, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 23: train loss = 0.26, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 24: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 25: train loss = 0.27, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 26: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[32m ++\u001b[0m\n",
      "Epoch 27: train loss = 0.29, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 28: train loss = 0.28, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 29: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 30: train loss = 0.27, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 31: train loss = 0.28, val loss = 0.28, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 32: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 33: train loss = 0.27, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 34: train loss = 0.27, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 35: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 36: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 37: train loss = 0.27, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 38: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 39: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n",
      "Epoch 40: train loss = 0.28, val loss = 0.27, AUC = 0.94\u001b[31m --\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classifier, train_loader, val_loader = train(\n",
    "    simulator=neutral_simulator,\n",
    "    prior=prior,\n",
    "    num_simulations=10000,\n",
    "    classifier=classifier, \n",
    "    n_epochs=40, \n",
    "    batch_size=500, \n",
    "    device=\"cuda\", \n",
    "    learning_rate=0.001,\n",
    "    num_workers=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "experimental-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "\n",
    "def classify(theta, simulator, num_experiments=100):\n",
    "    x = np.vstack([simulator(theta) for _ in range(num_experiments)])\n",
    "    with torch.no_grad():\n",
    "        output = classifier(torch.FloatTensor(x).unsqueeze(1).to(\"cuda\"))\n",
    "    print(f\"p(x|theta=1) = {(output > 0.5).float().mean().item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-portsmouth",
   "metadata": {},
   "source": [
    "Test the performance of the model by classifying some generated samples. Given some $\\theta_i$, we simulate 100 samples, and use the trained classifier to 'predict' whether they are examples of neutral evolution or not. The function returns the fraction of biased samples. \n",
    "\n",
    "First, let's test whether the model accurately classifies neutral samples to be neutral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dominant-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(x|theta=1) = 0.020\n"
     ]
    }
   ],
   "source": [
    "theta = torch.tensor([0., 0.01, 0.5])\n",
    "classify(theta, neutral_simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-rouge",
   "metadata": {},
   "source": [
    "That seems to be working. And what about non-neutral, biased samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "unusual-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(x|theta=1) = 1.000\n"
     ]
    }
   ],
   "source": [
    "theta = torch.tensor([0.1, 0.01, 0.5])\n",
    "classify(theta, neutral_simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-tonight",
   "metadata": {},
   "source": [
    "Also not bad. \n",
    "\n",
    "Next, we generate samples with the age-structured model and see whether the model (which was only trained on samples _without_ age structure) can still accurately discriminate between neutral an non-neutral samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "satisfactory-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_structured_simulator = Simulator(\n",
    "    n_agents=1000, \n",
    "    timesteps=1,\n",
    "    age_window=(0, 2),\n",
    "    disable_pbar=True,\n",
    "    summarize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "useful-ballot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(x|theta=1) = 0.010\n"
     ]
    }
   ],
   "source": [
    "theta = torch.tensor([0., 0.01, 0.5])\n",
    "classify(theta, age_structured_simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cosmetic-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(x|theta=1) = 0.990\n"
     ]
    }
   ],
   "source": [
    "theta = torch.tensor([0.1, 0.01, 0.5])\n",
    "classify(theta, age_structured_simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-biography",
   "metadata": {},
   "source": [
    "The first preliminary results suggest that the performance of the classifier is not strongly affected by age structure. Let's look at that in some more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
